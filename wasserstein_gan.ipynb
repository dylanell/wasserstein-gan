{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network\n",
    "In this notebook, we train the [Improved Wasserstein GAN](https://arxiv.org/pdf/1704.00028.pdf) on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What even is a Generative Adversarial Network (GAN)?\n",
    "A GAN is a neural network model consisting of two parts; a generator and a critic (also called a discriminator depending on the specific GAN model). The generator is trained to generate (*wow*) novel instances of data that look real compared to some reference training dataset. In order to \"sample\" instances of this data from the generator model, the inputs from the model are actually sampled from a prior distribution (typically Gaussian) which then produces the \"sampled\" batch of output data. The critic is trained to be able to discern between data produced from the generator and data selected from the reference training dataset. These two models are pitted against each other---as one improves, so does the other and at the end of training you get a generator that can produce realistic looking data. For example, GAN's are usually trained on a specific image dataset in order to produce novel images that look like realistic samples from the training dataset. \n",
    "\n",
    "More specifically, if we have some training dataset consisting of \"real\" data (i.e. images of dogs), we say this data belongs to some probability distribution of occurrence in which zero probability is assigned for data outside this distribution (i.e. images of lamps) and non-zero probability is assigned for data within this distribution (i.e. images of golden retrievers). Given some metric that measures the divergence between two probability distributions, the goal of the critic is to learn output such that this divergence is maximized and the goal of the generator is the exact opposite; to learn output such that this divergence metric is minimized. This creates a min-max game between the critic and generator, therefore successful training requires a sort of \"balance of power\" between the two models by preventing one from moving too far along its objective before the other is updated again. \n",
    "\n",
    "In the [original GAN implementation](https://arxiv.org/pdf/1406.2661.pdf), the critic model is actually refered to as the *discriminator* model, as it is trained to classify whether an input image is \"fake\" (from the generator), or \"real\" from the training dataset. This approach is successful, but the presence of sigmoids at the output of the discriminator can lead to saturation during traing of some complex data distributions, leading to instability and difficulty training in some cases. \n",
    "\n",
    "The Improved Wasserstein GAN is introduced to remedy some of the instability issues faced by the original GAN by defining a different objective for the discriminator. This new objective involves training the discriminator to directly estimate the divergence between the probability distributions in which two batches of data are sampled from, therefore the name \"discriminator\" is changed to \"critic\" as this model now outputs an unbounded real value instead of a probability used for classification. In this setting, the critic is given a batch of \"real\" data sampled from the training dataset, and a batch of \"fake\" data sampled from the generator model, and its job is to estimate the [Wasserstein Distance](https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence) between the probability distributions in which these two batches of data are sampled from. If the data in both batches belong to the same distribution, the critic should output zero since there should be no measured divergence between two identical probability distributions. This property is used to construct the objective functions used for the Improved Wasserstein GAN model. Below, we outline the components that make up this objective function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function\n",
    "The Improved Wasserstein GAN objective function is mainly two-fold with an added regularization term for stability (hence, the \"improved\" status). We briefly describe each part of the objectove function below, then dive right into training. \n",
    "\n",
    "1. **[Wasserstein Distance](https://en.wikipedia.org/wiki/Wasserstein_metric)([Earth Movers Distance](https://en.wikipedia.org/wiki/Earth_mover%27s_distance)):** This is a metric used to measure the divergence between two probability distributions. The value is non-zero for two probability distributions that are even slightly different, and zero for two identical probability distributions. In practice, directly computing the divergence betwene two distributions is often intractable, therefore when training a Wasserstein GAN the problem is cleverly set up such that the critic learns to compute an estimate of the Wasserstein distance between the distributions that produce two batches of samples. In reality, the critic actually learns some arbritrary divergence metric that is useful for training in which the units of measure do not really matter at all. We show why this is this case below, by defining the objective for the critic and generator in terms of this shared, arbritrary divergence estimate. \n",
    "\n",
    "For a critic, $C_\\theta$, with parameters $\\theta$, \"real data\" input batch, $x_r$, and \"fake data\" input batch, $x_f$, the estimated Wasserstein distance estimate, $W$, between the distributions from which the two input batches were samples is expressed by:\n",
    "\n",
    "\\begin{align}\n",
    "W(x_r, x_f) = C_\\theta(x_r) - C_\\theta(x_f).\n",
    "\\tag{1}\n",
    "\\label{eq:wass_dist}\n",
    "\\end{align}\n",
    "\n",
    "A nice way to remember the Wasserstein distance estimate in terms of critic output is \"real minus fake\".\n",
    "\n",
    "Since $x_f$ is sampled from the generator network, we can substitute $x_f = G_\\phi(z)$ for generator network, $G$, with parameters $\\phi$, and inputs, $z$, sampled from a prior distribution. Both the critic and generator objectives are defined in terms of eq. \\ref{eq:wass_dist}, therefore we mention again that the units of measure for the estimate in eq. \\ref{eq:wass_dist} do not matter to us.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Training was perfomed separate from this notebook on a CUDA enabled machine using a NVIDIA GeForce GTX 1060 GPU for acceleration. Overall, it took a little over 2 hours to complete 100 training epochs over the MNIST training dataset---a large imporvement from the projected ~33 hours it would have taken on an Intel Core i7. Trained model weights were saved and are loaded to to the critic and generator models used in this notebook.\n",
    "\n",
    "Training is done by running the `train.py` script which accepts a number of training options as arguments and runs the training loop on an instance of the `WassersteinGAN` class. An example usage of the `train.py` script is shown below, which trains a Wasserstein GAN model named 'glados_wgan' for 100 epochs with a batch size of 128.\n",
    "\n",
    "`python train.py --name glados_wgan --ne 100 --bs 128`\n",
    "\n",
    "There are a number of additional training options that can be configured listed within the `train.py` file. The overall structure of the Wasserstein GAN, loss functions, and the training loop can be seen in the `wasserstein_gan.py` model class file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup.\n",
    "Package imports, relative imports, and some paremeter definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import plotly\n",
    "\n",
    "# relative imports\n",
    "from cnn import CNN\n",
    "from transpose_cnn import TransposeCNN\n",
    "from dataloader_utils import make_mnist_dataloaders\n",
    "from data_utils import tile_images\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 1\n",
    "DATA_DIR = '/tmp/mnist_data/'\n",
    "NUM_CHAN = 1\n",
    "Z_DIM = 128\n",
    "CRITIC_MODEL_FILE = '/home/dylan/trained_model_files/pytorch/glados/glados_gan/glados_wgan_critic.pt'\n",
    "GENERATOR_MODEL_FILE = '/home/dylan/trained_model_files/pytorch/glados/glados_gan/glados_wgan_generator.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders.\n",
    "Below, we use the custom function `make_mnist_dataloaders()` defined in `dataloader_utils.py` to return iteratable Pytorch dataloaders for the MNIST dataset. On the first run of the below block of code, you may get an error saying something like `FloatProgress not found. Please update jupyter and ipywidgets`, caused by the current install of jupyterlab being slightly out of date. A link should be provided in the error message with instructions to update, but if using *conda* for Python package management this problem can be fixed by installing the update via command line with:\n",
    "\n",
    "`conda install -c conda-forge ipywidgets`\n",
    "\n",
    "Additionally, on the first run of the below code block and after the above error is fixed, you will see progress bars indicating the initial download of the MNIST datasets. By default, this path is set to `/tmp/mnist_data`. Running the below code block after the initial data download should return no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize MNIST dataloaders\n",
    "train_loader, test_loader = make_mnist_dataloaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and load pre-trained critic and generator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize critic (CNN) model\n",
    "critic = CNN(\n",
    "    in_chan=NUM_CHAN,\n",
    "    out_dim=1,\n",
    "    out_act=None\n",
    ")\n",
    "\n",
    "# initialize generator (TransposeCNN) model\n",
    "generator = TransposeCNN(\n",
    "    in_dim=Z_DIM,\n",
    "    out_chan=NUM_CHAN,\n",
    "    out_act=torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "# load trained weights files\n",
    "critic.load_state_dict(torch.load(CRITIC_MODEL_FILE, map_location=torch.device('cpu')))\n",
    "generator.load_state_dict(torch.load(GENERATOR_MODEL_FILE, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by generating some fake images and comparing them to some real images. \n",
    "We start by defining a normal distribution to sample our `Z_DIM` dimensional inputs for the generator. Then we generate `BATCH_SIZE` fake images using a sample from our normal distribution as inputs to the generator and we collect `BATCH_SIZE` real images directly from the MNIST training set dataloader. As these images are currently in the form of Pytorch tensors, we must call `detach()` and `numpy()` on them to remove their Pytorch functionality dependence and convert them to numpy arrays before reorganizing them into a nicely tiled single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize zdim dimensional normal distribution to sample generator inputs\n",
    "z_dist = torch.distributions.normal.Normal(\n",
    "    torch.zeros(BATCH_SIZE, Z_DIM),\n",
    "    torch.ones(BATCH_SIZE, Z_DIM)\n",
    ")\n",
    "\n",
    "# feed a batch of z samples to the generator\n",
    "fake_images = generator(z_dist.sample())\n",
    "\n",
    "# get a batch of real images from the MNIST training set\n",
    "real_images = iter(train_loader).next()[0]\n",
    "\n",
    "# detach and convert image batches to numpy arrays and tile them into one image\n",
    "fake_images_tiled = tile_images(fake_images.detach().numpy())\n",
    "real_images_tiled = tile_images(real_images.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
