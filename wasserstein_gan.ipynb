{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network\n",
    "Implementation of the [Improved Wasserstein GAN](https://arxiv.org/pdf/1704.00028.pdf) on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] using 'cpu' device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# relative imports\n",
    "from cnn import CNN\n",
    "from transpose_cnn import TransposeCNN\n",
    "from dataloader_utils import make_mnist_dataloaders\n",
    "\n",
    "# constants and hyperparameters\n",
    "LEARN_RATE = 1e-4\n",
    "BATCH_SIZE = 64\n",
    "NUM_TRAIN = 60000\n",
    "NUM_TEST = 10000\n",
    "NUM_WORKERS = 4\n",
    "NUM_CHAN =1\n",
    "NUM_EPOCHS = 20\n",
    "Z_DIM = 128\n",
    "\n",
    "# try to get gpu device, if not just use cpu\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print('[INFO] using \\'{}\\' device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] critic structure \n",
      "CNN(\n",
      "  (hid_act): ReLU()\n",
      "  (out_act): Identity()\n",
      "  (conv_1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv_2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (norm_1): Identity()\n",
      "  (norm_2): Identity()\n",
      "  (norm_3): Identity()\n",
      "  (norm_4): Identity()\n",
      "  (norm_5): Identity()\n",
      "  (fc_1): Linear(in_features=2048, out_features=1, bias=True)\n",
      ")\n",
      "[INFO] generator structure \n",
      "TransposeCNN(\n",
      "  (hid_act): ReLU()\n",
      "  (out_act): Tanh()\n",
      "  (fc_1): Linear(in_features=128, out_features=2048, bias=True)\n",
      "  (conv_1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_2): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_3): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_4): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (conv_5): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (norm_1): LayerNorm((512, 2, 2), eps=1e-05, elementwise_affine=True)\n",
      "  (norm_2): LayerNorm((256, 4, 4), eps=1e-05, elementwise_affine=True)\n",
      "  (norm_3): LayerNorm((128, 8, 8), eps=1e-05, elementwise_affine=True)\n",
      "  (norm_4): LayerNorm((64, 16, 16), eps=1e-05, elementwise_affine=True)\n",
      "  (norm_5): LayerNorm((32, 32, 32), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# initialize critic (CNN) model\n",
    "critic = CNN(\n",
    "    in_chan=NUM_CHAN, \n",
    "    out_dim=1, \n",
    "    hid_act=torch.nn.ReLU(), \n",
    "    out_act=torch.nn.Identity(), \n",
    "    layer_norm=False\n",
    ")\n",
    "\n",
    "# initialize generator (TransposeCNN) model\n",
    "generator = TransposeCNN(\n",
    "    in_dim=Z_DIM,\n",
    "    out_chan=NUM_CHAN,\n",
    "    hid_act=torch.nn.ReLU(),\n",
    "    out_act=torch.nn.Tanh(),\n",
    "    layer_norm=True\n",
    ")\n",
    "\n",
    "print('[INFO] critic structure \\n{}'.format(critic))\n",
    "print('[INFO] generator structure \\n{}'.format(generator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataloaders\n",
    "Below, we use the custom function `make_mnist_dataloaders()` defined in `dataloader_utils.py` to return iteratable Pytorch dataloaders for the MNIST dataset. On the first run of the below block of code, you may get an error saying something like `FloatProgress not found. Please update jupyter and ipywidgets`, caused by the current install of jupyterlab being slightly out of date. A link should be provided in the error message with instructions to update, but if using *conda* for Python package management this problem can be fixed by installing the update via command line with:\n",
    "\n",
    "`conda install -c conda-forge ipywidgets`\n",
    "\n",
    "Additionally, on the first run of the below code block and after the above error is fixed, you will see progress bars indicating the initial download of the MNIST datasets. By default, this path is set to `/tmp/mnist_data`. Running the below code block after the initial data download should return no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = make_mnist_dataloaders(batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
