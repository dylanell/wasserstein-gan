{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wasserstein Generative Adversarial Network\n",
    "Exploration of the [Improved Wasserstein GAN](https://arxiv.org/pdf/1704.00028.pdf) trained on the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "Training was perfomed separate from this notebook on a CUDA enabled machine using a NVIDIA GeForce GTX 1060 GPU for acceleration. Overall, it took a little over 2 hours to complete 100 training epochs over the MNIST training dataset---a large imporvement from the projected ~33 hours it would have taken on an Intel Core i7. Trained model weights were saved and are loaded to to the critic and generator models used in this notebook.\n",
    "\n",
    "Training is done by running the `train.py` script which accepts a number of training options as arguments and runs the training loop on an instance of the `WassersteinGAN` class. An example usage of the `train.py` script is shown below, which trains a Wasserstein GAN model named 'glados_wgan' for 100 epochs with a batch size of 128.\n",
    "\n",
    "`python train.py --name glados_wgan --ne 100 --bs 128`\n",
    "\n",
    "There are a number of additional training options that can be configured listed within the `train.py` file. The overall structure of the Wasserstein GAN, loss functions, and the training loop can be seen in the `wasserstein_gan.py` model class file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup.\n",
    "Package imports, relative imports, and some paremeter definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import plotly\n",
    "\n",
    "# relative imports\n",
    "from cnn import CNN\n",
    "from transpose_cnn import TransposeCNN\n",
    "from dataloader_utils import make_mnist_dataloaders\n",
    "from data_utils import tile_images\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 1\n",
    "DATA_DIR = '/tmp/mnist_data/'\n",
    "NUM_CHAN = 1\n",
    "Z_DIM = 128\n",
    "CRITIC_MODEL_FILE = '/tmp/glados_wgan_critic.pt'\n",
    "GENERATOR_MODEL_FILE = '/tmp/glados_wgan_generator.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataloaders.\n",
    "Below, we use the custom function `make_mnist_dataloaders()` defined in `dataloader_utils.py` to return iteratable Pytorch dataloaders for the MNIST dataset. On the first run of the below block of code, you may get an error saying something like `FloatProgress not found. Please update jupyter and ipywidgets`, caused by the current install of jupyterlab being slightly out of date. A link should be provided in the error message with instructions to update, but if using *conda* for Python package management this problem can be fixed by installing the update via command line with:\n",
    "\n",
    "`conda install -c conda-forge ipywidgets`\n",
    "\n",
    "Additionally, on the first run of the below code block and after the above error is fixed, you will see progress bars indicating the initial download of the MNIST datasets. By default, this path is set to `/tmp/mnist_data`. Running the below code block after the initial data download should return no output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize MNIST dataloaders\n",
    "train_loader, test_loader = make_mnist_dataloaders(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    data_dir=DATA_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and load pre-trained critic and generator models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize critic (CNN) model\n",
    "critic = CNN(\n",
    "    in_chan=NUM_CHAN,\n",
    "    out_dim=1,\n",
    "    out_act=None\n",
    ")\n",
    "\n",
    "# initialize generator (TransposeCNN) model\n",
    "generator = TransposeCNN(\n",
    "    in_dim=Z_DIM,\n",
    "    out_chan=NUM_CHAN,\n",
    "    out_act=torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "# load trained weights files\n",
    "critic.load_state_dict(torch.load(CRITIC_MODEL_FILE, map_location=torch.device('cpu')))\n",
    "generator.load_state_dict(torch.load(GENERATOR_MODEL_FILE, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by generating some fake images and comparing them to some real images. \n",
    "We start by defining a normal distribution to sample our `Z_DIM` dimensional inputs for the generator. Then we generate `BATCH_SIZE` fake images using a sample from our normal distribution as inputs to the generator and we collect `BATCH_SIZE` real images directly from the MNIST training set dataloader. As these images are currently in the form of Pytorch tensors, we must call `detach()` and `numpy()` on them to remove their Pytorch functionality dependence and convert them to numpy arrays before reorganizing them into a nicely tiled single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize zdim dimensional normal distribution to sample generator inputs\n",
    "z_dist = torch.distributions.normal.Normal(\n",
    "    torch.zeros(BATCH_SIZE, Z_DIM),\n",
    "    torch.ones(BATCH_SIZE, Z_DIM)\n",
    ")\n",
    "\n",
    "# feed a batch of z samples to the generator\n",
    "fake_images = generator(z_dist.sample())\n",
    "\n",
    "# get a batch of real images from the MNIST training set\n",
    "real_images = iter(train_loader).next()[0]\n",
    "\n",
    "# detach and convert image batches to numpy arrays and tile them into one image\n",
    "fake_images_tiled = tile_images(fake_images.detach().numpy())\n",
    "real_images_tiled = tile_images(real_images.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
